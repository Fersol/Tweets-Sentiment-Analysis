{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import regex\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import artm\n",
    "import codecs\n",
    "from seaborn import heatmap\n",
    "import time\n",
    "from math import log\n",
    "import operator\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize\n",
    "from pymystem3 import Mystem\n",
    "import cPickle as pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "with open('extra_data/prepared_tweets.txt', 'r') as infile:\n",
    "    tweets = infile.readlines()\n",
    "    \n",
    "with open('extra_data/targets.txt', 'r') as infile:\n",
    "    y = infile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tweets, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(corpus):\n",
    "    corpus = [z.lower().replace('\\n','').split() for z in corpus]\n",
    "    return corpus\n",
    "\n",
    "x_train = cleanText(x_train)\n",
    "x_test = cleanText(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = [int(y.strip()) for y in y_train]\n",
    "y_test = [int(y.strip()) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_WORD_LEN = 2\n",
    "MAX_WORD_LEN = 20\n",
    "MIN_WORD_COUNT = 5\n",
    "def filter_words_by_length(text):\n",
    "    return [word for word in text if len(word) >= MIN_WORD_LEN and len(word) <= MAX_WORD_LEN]\n",
    "def filter_texts_by_length(texts):\n",
    "    return [text for text in texts if len(text) >= MIN_WORD_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = [filter_words_by_length(text) for text in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181467"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = filter_texts_by_length(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167743"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формируем словарь коллекции из (1,3) - грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dict(data): \n",
    "    corpus_dict = defaultdict(int)\n",
    "    for text in data:\n",
    "        MIN_WORD_LEN = 3\n",
    "        text = [word for word in text if len(word) >= MIN_WORD_LEN]\n",
    "        bigrams = [k[0]+\"_\"+k[1] for k in zip(text[:-1], text[1:])]\n",
    "        trigrams = [k[0]+\"_\"+k[1]+\"_\"+k[2] for k in zip(text[:-2], text[1:-1], text[2:])]\n",
    "        terms = text + bigrams + trigrams\n",
    "        for term in terms:\n",
    "            corpus_dict[term]+=1\n",
    "    return corpus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_dict = make_dict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1923175"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_vocab(corpus_dict):\n",
    "    vocab = defaultdict(int)\n",
    "    MIN_DF = 5\n",
    "    for term, freq in corpus_dict.iteritems():\n",
    "        if freq >= MIN_DF and len(term) >= MIN_WORD_LEN:\n",
    "            vocab[term]+=1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = filter_vocab(corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab.keys()[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формируем файлы в формате Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vw(texts):\n",
    "    output_vw = []\n",
    "    MIN_DF = 5\n",
    "    MIN_WORD_LEN = 3\n",
    "    for index, text in tqdm.tqdm(enumerate(texts)):\n",
    "        vw_dict = defaultdict(int)\n",
    "        text = [word for word in text if len(word.strip()) >= MIN_WORD_LEN]\n",
    "        bigrams = [k[0]+\"_\"+k[1] for k in zip(text[:-1], text[1:])]\n",
    "        trigrams = [k[0]+\"_\"+k[1]+\"_\"+k[2] for k in zip(text[:-2], text[1:-1], text[2:])]\n",
    "        terms = text + bigrams + trigrams\n",
    "        #print ' '.join(terms)\n",
    "        for word in terms:\n",
    "            vw_dict[word]+=1\n",
    "        sentence = [u\"{}:{}\".format(term.decode('utf-8'), frequency) for term, frequency in vw_dict.iteritems()\n",
    "                   if corpus_dict[term] >= MIN_DF ]\n",
    "        output_vw.append(u\"{} |@default_class {}\".format(index, \" \".join(sentence)))\n",
    "    return output_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167743it [00:38, 4306.21it/s]\n"
     ]
    }
   ],
   "source": [
    "vw_train = make_vw(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167743\n"
     ]
    }
   ],
   "source": [
    "print len(vw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"extra_data/\" + \"vw.txt\", \"w\", encoding=\"utf-8\") as output:\n",
    "    print >> output, \"\\n\".join(vw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"extra_data/\" + \"vocab.txt\", \"w\", encoding=\"utf-8\") as output:\n",
    "    print >> output, \"\\n\".join([key.decode('utf-8') for key in vocab.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FOLDER_DATA = 'extra_data/'\n",
    "FOLDER_BATCHES = 'batches/'\n",
    "PATH_TO_VW = FOLDER_DATA + 'vw.txt'\n",
    "FOLDER_BATCHES = FOLDER_BATCHES + \"replies\"\n",
    "VOCAB_PATH = FOLDER_DATA + \"vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bv = artm.BatchVectorizer(data_path=PATH_TO_VW, data_format=\"vowpal_wabbit\",\n",
    "                          target_folder=FOLDER_BATCHES, gather_dictionary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
